# -*- coding: utf-8 -*-
"""AQI_MAP_BOUND.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pq9DOocttCFnKbUMpDw-Ski-mgcj9Sae

# Data Scraping Through Map Bound
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
import xgboost as xgb
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
from xgboost import XGBRegressor
from sklearn.linear_model import LogisticRegression
import plotly.express as px
import folium
from folium.plugins import MarkerCluster
import os
import xgboost as xg
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings("ignore")
import requests
import time

API_TOKEN = '6006a1a469ec4d9df77382f5a4b196c544a1430f'
latlng = "6.554,68.176,35.674,97.395"
def safe_request(url, retries=3, backoff=2):
    for attempt in range(retries):
        try:
            res = requests.get(url, timeout=10)
            if res.status_code == 200:
                return res
        except Exception as e:
            print(f"   Error on attempt {attempt+1}: {e}")
        time.sleep(backoff * (attempt + 1))
    return None
try:
    print("Fetching station list...")
    resp = safe_request(f"https://api.waqi.info/map/bounds?token={API_TOKEN}&latlng={latlng}")
    if resp:
        stations = resp.json().get("data", [])
        print(f"Found {len(stations)} stations")
    else:
        print("Could not fetch stations.")
        stations = []
except Exception as e:
    print(f" Failed to fetch station list: {e}")
    stations = []

records = []

for i, st in enumerate(stations, start=1):
    sid = st.get('uid')
    station_name = st.get('station', {}).get('name')

    if sid and station_name:
        print(f"📡 ({i}/{len(stations)}) Fetching data for {station_name} (sid: {sid})")

        url = f"https://api.waqi.info/feed/@{sid}/?token={API_TOKEN}"
        res = safe_request(url)

        if res:
            data = res.json()
            if data.get('status') == 'ok':
                aqi_data = data['data']
                iaqi = aqi_data.get('iaqi', {})

                record = {
                    'Station': station_name,
                    'Lat': st.get('lat'),
                    'Lon': st.get('lon'),
                    'AQI': aqi_data.get('aqi'),
                    'PM2.5': iaqi.get('pm25', {}).get('v'),
                    'PM10': iaqi.get('pm10', {}).get('v'),
                    'CO': iaqi.get('co', {}).get('v'),
                    'NO2': iaqi.get('no2', {}).get('v'),
                    'SO2': iaqi.get('so2', {}).get('v'),
                    'O3': iaqi.get('o3', {}).get('v'),
                    'Timestamp': aqi_data.get('time', {}).get('s')
                }
                records.append(record)
            else:
                print(f" No AQI data available for {station_name}")
        else:
            print(f" Failed to get data for {station_name} (sid: {sid})")
        time.sleep(1.2)
if records:
    df = pd.DataFrame(records)
    print(" Sample Data:")
    print(df.head())
    df.to_csv("india_waqi_data.csv", index=False)
    print(" Data saved to 'india_waqi_data.csv'")
else:
    print(" No valid data collected.")

df = pd.read_csv("india_waqi_data.csv")
def get_aqi_category(aqi):
    try:
        aqi = float(aqi)
        if aqi <= 50:
            return "Good"
        elif aqi <= 100:
            return "Moderate"
        elif aqi <= 200:
            return "Unhealthy for Sensitive Groups"
        elif aqi <= 300:
            return "Unhealthy"
        elif aqi <= 400:
            return "Very Unhealthy"
        else:
            return "Hazardous"
    except:
        return "Unknown"

def get_color(aqi):
    try:
        aqi = float(aqi)
        if aqi <= 50:
            return 'green'
        elif aqi <= 100:
            return 'yellow'
        elif aqi <= 200:
            return 'orange'
        elif aqi <= 300:
            return 'red'
        elif aqi <= 400:
            return 'purple'
        else:
            return 'maroon'
    except:
        return 'gray'
m = folium.Map(location=[22.9734, 78.6569], zoom_start=5, tiles='cartodbpositron')
marker_cluster = MarkerCluster().add_to(m)
for _, row in df.iterrows():
    if pd.notnull(row['Lat']) and pd.notnull(row['Lon']):
        popup_content = f"""
        <b>{row['Station']}</b><br>
        <b>AQI:</b> {row['AQI']}<br>
        <b>PM2.5:</b> {row['PM2.5']}<br>
        <b>PM10:</b> {row['PM10']}<br>
        <b>CO:</b> {row['CO']}<br>
        <b>NO2:</b> {row['NO2']}<br>
        <b>SO2:</b> {row['SO2']}<br>
        <b>O3:</b> {row['O3']}
        """
        folium.CircleMarker(
            location=[row['Lat'], row['Lon']],
            radius=5,
            color=get_color(row['AQI']),
            fill=True,
            fill_color=get_color(row['AQI']),
            fill_opacity=0.7,
            popup=folium.Popup(popup_content, max_width=300)
        ).add_to(marker_cluster)
m.fit_bounds([[df['Lat'].min(), df['Lon'].min()], [df['Lat'].max(), df['Lon'].max()]])
m

df.head()

df.to_csv("india_waqi_data.csv", index=False, mode='a', header=not os.path.exists("india_waqi_data.csv"))

df = pd.read_csv("india_waqi_data.csv", on_bad_lines='skip')

"""# Pre-Processing"""

expected_columns = 13
with open("india_waqi_data.csv", 'r') as file:
    for i, line in enumerate(file):
        fields = line.strip().split(',')
        if len(fields) != expected_columns:
            print(f" Line {i+1} has {len(fields)} columns: {fields}")

df = pd.read_csv("india_waqi_data.csv", on_bad_lines='skip')
numeric_cols = ['AQI', 'PM2.5', 'PM10', 'O3', 'NO2', 'SO2', 'CO']
for col in numeric_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')

df_clean = df.dropna(subset=numeric_cols, how='all')

print(df_clean[numeric_cols].dtypes)
print(df_clean[numeric_cols].head())

print(df.isnull().sum())

print("Null values before filling:\n", df.isnull().sum())
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns

for col in numeric_cols:
    if df[col].isnull().sum() > 0:
        mean_val = df[col].mean()
        df[col].fillna(mean_val, inplace=True)
        print(f"Filled nulls in '{col}' with mean value: {mean_val:.2f}")
print("\nNull values after filling:\n", df.isnull().sum())

# numeric_df = df.select_dtypes(include='number')

# correlations = numeric_df.corr()['AQI'].sort_values(ascending=False)
# print(correlations)

# numeric_df = df.select_dtypes(include='number')
# corr_matrix = numeric_df.corr()
# plt.figure(figsize=(10, 8))
# sns.heatmap(
#     corr_matrix[['AQI']].reindex(corr_matrix['AQI'].abs().sort_values(ascending=False).index),

#     annot=True,
#     cmap='magma',
#     center=0,
#     linewidths=0.5,
#     fmt=".3f"
# )

# plt.title("Correlation of Each Feature with AQI", fontsize=14)
# plt.tight_layout()
# plt.show()

pollutants = ['PM2.5', 'PM10', 'O3', 'NO2', 'SO2', 'CO', 'AQI']
df_melted = df[pollutants].melt(var_name='Pollutant', value_name='Value')
plt.figure(figsize=(12, 6))
sns.boxplot(x='Pollutant', y='Value', data=df_melted, palette='Set2')
plt.title('Boxplots for Pollutants and AQI')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

def remove_outliers_percentile(df, lower_percentile=0.01, upper_percentile=0.99):
    df = df.copy()
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    for col in numeric_cols:
        lower = df[col].quantile(lower_percentile)
        upper = df[col].quantile(upper_percentile)
        df = df[(df[col] >= lower) & (df[col] <= upper)]
    return df

def remove_outliers_iqr_repeated(df, max_iter=5):
    df = df.copy()
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    for _ in range(max_iter):
        rows_before = df.shape[0]
        for col in numeric_cols:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 1.5 * IQR
            upper = Q3 + 1.5 * IQR
            df = df[(df[col] >= lower) & (df[col] <= upper)]
        if df.shape[0] == rows_before:
            break
    return df
df_trimmed = remove_outliers_percentile(df)
df_cleaned = remove_outliers_iqr_repeated(df_trimmed)

plt.figure(figsize=(14, 6))

sns.boxplot(
    data=df_cleaned.select_dtypes(include=['float64', 'int64']),
    palette='Set3'
)

plt.title("Boxplots After Strict Outlier Removal (Percentile + Repeated IQR)")
plt.xlabel("Pollutant")
plt.ylabel("Concentration")
plt.tight_layout()
plt.grid(True)
plt.show()

"""# EDA"""

plt.figure(figsize=(10, 6))
sns.histplot(df['AQI'], bins=30, kde=True,color='darkblue')
plt.title('Distribution of AQI values')
plt.xlabel('AQI')
plt.ylabel('Frequency')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
avg_aqi_by_station = (
    df.groupby('Station')['AQI']
    .mean()
    .sort_values(ascending=False)
    .reset_index()
)
plt.figure(figsize=(18, 8))
sns.barplot(
    x='Station',
    y='AQI',
    data=avg_aqi_by_station,
    palette='Set2'
)
plt.xticks(rotation=90, ha='center')
plt.xlabel('Station', fontsize=12)
plt.ylabel('Average AQI', fontsize=12)
plt.title('🌫️ Average AQI by Station', fontsize=16, weight='bold')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

avg_aqi_by_station = (
    df.groupby('Station')['AQI']
    .mean()
    .sort_values(ascending=False)
    .reset_index()
)
plt.figure(figsize=(20, 10))
sns.barplot(
    x='Station',
    y='AQI',
    data=avg_aqi_by_station,
    palette='viridis',
    width=0.4
)
plt.xticks(rotation=90, ha='center', fontsize=9)
plt.xlabel('Station', fontsize=14)
plt.ylabel('Average AQI', fontsize=14)
plt.title('🌫️ Average AQI by Station', fontsize=18, weight='bold', pad=20)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

pollutant_cols = ['PM10', 'NO2', 'PM2.5', 'CO', 'SO2', 'O3']
df_melted = df.melt(
    id_vars=['Station'],
    value_vars=pollutant_cols,
    var_name='Pollutant',
    value_name='Concentration'
).dropna(subset=['Concentration'])
pollutant_counts = (
    df_melted
    .groupby(['Station', 'Pollutant'])
    .size()
    .unstack(fill_value=0)
)
pollutant_counts['Total'] = pollutant_counts.sum(axis=1)
pollutant_counts = pollutant_counts.sort_values(by='Total', ascending=False).drop(columns='Total')
plt.figure(figsize=(18, 8))
colors = sns.color_palette("Set2", len(pollutant_cols))

pollutant_counts.plot(
    kind='bar',
    stacked=True,
    color=colors,
    figsize=(18, 8)
)

plt.title(' Predominant Pollutants Across Indian AQI Stations', fontsize=16, weight='bold')
plt.xlabel('Station', fontsize=12)
plt.ylabel('Pollutant Occurrence Count', fontsize=12)
plt.xticks(rotation=90, ha='center')
plt.legend(title='Pollutant', bbox_to_anchor=(1.02, 1), loc='upper left')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

fig = px.scatter(
    df,
    x='Station',
    y='AQI',

    hover_data=['PM2.5', 'PM10', 'CO', 'NO2','O3','SO2'],  # optional
    title='AQI vs Station'
)
fig.update_layout(xaxis_tickangle=-45)
fig.show()

"""# Model Testing"""

df_model = df_cleaned.copy()
le = LabelEncoder()
df_model['Station'] = le.fit_transform(df_model['Station'].astype(str))
X = df_model.drop('AQI', axis=1).select_dtypes(include=['number'])
y = df_model['AQI']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
model = KNeighborsRegressor(n_neighbors=5)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(" MSE:", mean_squared_error(y_test, y_pred))
print(" R² Score:", r2_score(y_test, y_pred))

df_model = df_cleaned.copy()
le = LabelEncoder()
df_model['Station'] = le.fit_transform(df_model['Station'].astype(str))

X = df_model.drop('AQI', axis=1).select_dtypes(include=['number'])
y = df_model['AQI']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred = lr_model.predict(X_test)
print(" MSE:", mean_squared_error(y_test, y_pred))
print(" R² Score:", r2_score(y_test, y_pred))

df_model = df_cleaned.copy()
le = LabelEncoder()
df_model['Station'] = le.fit_transform(df_model['Station'].astype(str))
X = df_model.drop('AQI', axis=1).select_dtypes(include=['number'])
y = df_model['AQI']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
rf_model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)
print(" MSE:", mean_squared_error(y_test, y_pred))
print("R² Score:", r2_score(y_test, y_pred))

df_model = df_cleaned.copy()
le = LabelEncoder()
df_model['Station'] = le.fit_transform(df_model['Station'].astype(str))
X = df_model.drop('AQI', axis=1).select_dtypes(include=['number'])
y = df_model['AQI']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
xgb_model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    objective='reg:squarederror',
    random_state=42
)
xgb_model.fit(X_train, y_train)
y_pred = xgb_model.predict(X_test)
print(" MSE:", mean_squared_error(y_test, y_pred))
print(" R² Score:", r2_score(y_test, y_pred))

df_model = df_cleaned.copy()
le = LabelEncoder()
df_model['Station'] = le.fit_transform(df_model['Station'].astype(str))
X = df_model.drop('AQI', axis=1).select_dtypes(include=['number'])
y = df_model['AQI']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
dt_model = DecisionTreeRegressor(max_depth=None, random_state=42)
dt_model.fit(X_train, y_train)
y_pred = dt_model.predict(X_test)
print(" MSE:", mean_squared_error(y_test, y_pred))
print("R² Score:", r2_score(y_test, y_pred))

df_model = df_cleaned.copy()
le = LabelEncoder()
df_model['Station'] = le.fit_transform(df_model['Station'].astype(str))
X = df_model.drop('AQI', axis=1).select_dtypes(include=['number'])
y = df_model['AQI']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
svr_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_model.fit(X_train, y_train)
y_pred = svr_model.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))
print(" R² Score:", r2_score(y_test, y_pred))

import joblib
joblib.dump(model, 'random_forest_model.pkl')
print(" Model trained and saved as 'random_forest_model.pkl'")

df = pd.read_csv("/content/india_waqi_data.csv")
df.replace('-', pd.NA, inplace=True)
for col in ['PM2.5', 'PM10', 'CO', 'NO2', 'SO2', 'O3', 'AQI', 'Lat', 'Lon']:
    df[col] = pd.to_numeric(df[col], errors='coerce')
df["Temperature"] = 25
def ppb_to_ugm3(ppb, mw, temp):
    return (ppb * mw * 273) / (22.4 * (273 + temp))

df["CO"] = ppb_to_ugm3(df["CO"], 28.01, df["Temperature"])
df["NO2"] = ppb_to_ugm3(df["NO2"], 46.01, df["Temperature"])
df["SO2"] = ppb_to_ugm3(df["SO2"], 64.07, df["Temperature"])
df["O3"] = ppb_to_ugm3(df["O3"], 48.00, df["Temperature"])
df.dropna(subset=['PM2.5', 'PM10', 'CO', 'NO2', 'SO2', 'O3', 'AQI', 'Lat', 'Lon'], inplace=True)
df.to_csv("cleaned_india_waqi.csv", index=False)
features = ['PM2.5', 'PM10', 'CO', 'NO2', 'SO2', 'O3']
X = df[features]
y = df['AQI']
model = RandomForestRegressor()
model.fit(X, y)
joblib.dump(model, 'random_forest_model.pkl')
with open("app.py", "w") as f:
    f.write('''
import streamlit as st
import pandas as pd
import joblib
import folium
from streamlit_folium import st_folium

st.set_page_config(layout="wide")
st.title(" AQI Prediction")

model = joblib.load("random_forest_model.pkl")
df = pd.read_csv("cleaned_india_waqi.csv")

# Convert ppb ➝ µg/m³
def ppb_to_ugm3(ppb, mw, temp):
    return (ppb * mw * 273) / (22.4 * (273 + temp))

with st.form("predict_form"):
    st.subheader("🔍 Enter pollutant values:")
    col1, col2, col3 = st.columns(3)
    with col1:
        pm25 = st.number_input("PM2.5 (µg/m³)", min_value=0.0)
        pm10 = st.number_input("PM10 (µg/m³)", min_value=0.0)
    with col2:
        co_ppb = st.number_input("CO (ppb)", min_value=0.0)
        no2_ppb = st.number_input("NO2 (ppb)", min_value=0.0)
    with col3:
        so2_ppb = st.number_input("SO2 (ppb)", min_value=0.0)
        o3_ppb = st.number_input("O3 (ppb)", min_value=0.0)
    temperature = st.slider("Temperature (°C)", 0, 50, 25)
    submitted = st.form_submit_button("🎯 Predict AQI")

if submitted:
    co = ppb_to_ugm3(co_ppb, 28.01, temperature)
    no2 = ppb_to_ugm3(no2_ppb, 46.01, temperature)
    so2 = ppb_to_ugm3(so2_ppb, 64.07, temperature)
    o3 = ppb_to_ugm3(o3_ppb, 48.00, temperature)

    input_data = [[pm25, pm10, co, no2, so2, o3]]
    predicted_aqi = model.predict(input_data)[0]
    st.success(f"🎯 Predicted AQI: {predicted_aqi:.2f}")

    df["diff"] = abs(df["AQI"] - predicted_aqi)
    filtered_df = df.sort_values("diff").head(10)

    # Closest stations
    st.markdown("### 🗺️ Stations with Closest AQI")
    m = folium.Map(location=[filtered_df["Lat"].mean(), filtered_df["Lon"].mean()], zoom_start=5)
    for _, row in filtered_df.iterrows():
        folium.Marker(
            location=[row["Lat"], row["Lon"]],
            popup=f"{row['Station']}: AQI {row['AQI']:.0f}",
            tooltip=row["Station"]
        ).add_to(m)
    st_folium(m, width=1000)
else:
    st.markdown("### 🌐 All AQI Monitoring Stations")
    m = folium.Map(location=[df["Lat"].mean(), df["Lon"].mean()], zoom_start=5)
    for _, row in df.iterrows():
        folium.CircleMarker(
            location=[row["Lat"], row["Lon"]],
            radius=5,
            color="red",
            fill=True,
            fill_color="blue",
            fill_opacity=0.7,
            popup=f"{row['Station']}: AQI {row['AQI']:.0f}"
        ).add_to(m)
    st_folium(m, width=1000)
''')
from pyngrok import ngrok
import threading, os

def run():
    os.system("streamlit run app.py")

threading.Thread(target=run).start()
ngrok.set_auth_token("2x6EV01DUlLWQ8pYTGSQqJU9KXC_5nWZQWdNSrTYimpfu421n")
public_url = ngrok.connect(8501)
print("🔗 Visit your app at:", public_url)